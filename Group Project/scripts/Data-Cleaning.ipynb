{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WASSA2017 had .txt files which had to be converted .csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BCQrrkxBLnkp"
   },
   "outputs": [],
   "source": [
    "# Importing the pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to combine the two datasets so that we would have more data to train our model and make better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P4uGDIa6Lv1K"
   },
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "text_emotion_recognition = pd.read_csv(\"../data/Original Data/text_emotion_recognition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "6Z28b5JCL4Ys",
    "outputId": "91342cad-2400-4025-ef58-f02af5945fef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweettype</th>\n",
       "      <th>score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10857.0</td>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10858.0</td>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10859.0</td>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10860.0</td>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10861.0</td>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                                              tweet  \\\n",
       "0           0  10857.0  @ZubairSabirPTI  pls dont insult the word 'Molna'   \n",
       "1           1  10858.0  @ArcticFantasy I would have almost took offens...   \n",
       "2           2  10859.0  @IllinoisLoyalty that Rutgers game was an abom...   \n",
       "3           3  10860.0  @CozanGaming that's what lisa asked before she...   \n",
       "4           4  10861.0  Sometimes I get mad over something so minuscul...   \n",
       "\n",
       "  tweettype  score  tweet_id sentiment author content  \n",
       "0     anger  0.479       NaN       NaN    NaN     NaN  \n",
       "1     anger  0.458       NaN       NaN    NaN     NaN  \n",
       "2     anger  0.562       NaN       NaN    NaN     NaN  \n",
       "3     anger  0.500       NaN       NaN    NaN     NaN  \n",
       "4     anger  0.708       NaN       NaN    NaN     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the raw dataset\n",
    "text_emotion_recognition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there were a few different columns between the datasets which had to be taken care of before we passed it down to our model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MKkZ7bsXVrGl"
   },
   "outputs": [],
   "source": [
    "#This funnction is utilized to drop the specified columns in the columns_to_drop list and returns the dataframe\n",
    "def dropColumns(df, columns_to_drop): \n",
    "  for column in columns_to_drop:\n",
    "    df.drop(column, inplace=True, axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V-Fd7cdMWA_Z"
   },
   "outputs": [],
   "source": [
    "#This function concatenates 2 columns and then eliminates the NaN value by first converting the contents of required 2 columns to string and then strips contents of column containing 'nan' off, and returns the dataframe\n",
    "def concatenateColumns(df, columns_dict): \n",
    "  for key,value in columns_dict.items():\n",
    "    df[key] = df[key].map(str) + ' ' + df[value].map(str)\n",
    "    df[key] = df[key].map(lambda x: x.lstrip('nan').rstrip('nan'))\n",
    "    df[key] = df[key].map(lambda x: x.lstrip(' ').rstrip(' '))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnecessary columns in the CROWDFLOWER dataset such as: tweet_id and author, WASSA2017 dataset such as id and score, were removed as they can hamper model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9z40r3YsbP-x",
    "outputId": "1a969a25-888c-4c2d-fa22-f236c9b6da6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweettype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43955</th>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43956</th>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43957</th>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43958</th>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43959</th>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43960 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      tweet  tweettype\n",
       "tweet_id                                                              \n",
       "0         @ZubairSabirPTI  pls dont insult the word 'Molna'      anger\n",
       "1         @ArcticFantasy I would have almost took offens...      anger\n",
       "2         @IllinoisLoyalty that Rutgers game was an abom...      anger\n",
       "3         @CozanGaming that's what lisa asked before she...      anger\n",
       "4         Sometimes I get mad over something so minuscul...      anger\n",
       "...                                                     ...        ...\n",
       "43955                                      @JohnLloydTaylor    neutral\n",
       "43956                        Happy Mothers Day  All my love       love\n",
       "43957     Happy Mother's Day to all the mommies out ther...       love\n",
       "43958     @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...  happiness\n",
       "43959     @mopedronin bullet train from tokyo    the gf ...       love\n",
       "\n",
       "[43960 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to be used as merging strategy\n",
    "columns_dict = {'tweet':'content', 'tweettype':'sentiment'}\n",
    "columns_to_drop = ['id','tweet_id','Unnamed: 0', 'author', 'sentiment', 'score', 'content'] \n",
    "text_emotion_recognition = concatenateColumns(text_emotion_recognition, columns_dict)\n",
    "\n",
    "#This follwoing three lines are error correction step beacuse earlier in the concatenateColumns, we stripped off strings 'nan' from the column tweettype. \n",
    "text_emotion_recognition['tweettype'] = text_emotion_recognition['tweettype'].str.replace('ger','anger') \n",
    "text_emotion_recognition['tweettype'] = text_emotion_recognition['tweettype'].str.replace('ananger','anger')\n",
    "text_emotion_recognition['tweettype'] = text_emotion_recognition['tweettype'].str.replace('fu','fun')\n",
    "\n",
    "# Extracting columns\n",
    "author = text_emotion_recognition['author']\n",
    "score = text_emotion_recognition['score']\n",
    "text_emotion_recognition.index.name = 'tweet_id'\n",
    "\n",
    "#Dropping columns\n",
    "text_emotion_recognition = dropColumns(text_emotion_recognition, columns_to_drop)\n",
    "text_emotion_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4PmXbfigLeK",
    "outputId": "a740dbf0-920b-44ea-8b08-e46373afabd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'sadness',\n",
       " 'empty',\n",
       " 'enthusiasm',\n",
       " 'neutral',\n",
       " 'worry',\n",
       " 'surprise',\n",
       " 'love',\n",
       " 'fun',\n",
       " 'hate',\n",
       " 'happiness',\n",
       " 'boredom',\n",
       " 'relief']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_categories = list(text_emotion_recognition['tweettype'].unique())\n",
    "sentiment_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after merging the 2 datasets, 15 categories were obtained namely: joy, happiness, enthusiasm, fun, sadness, worry, neutral, empty, hate, anger, fear, love boredom, relief, surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QIc5LKANhWcz"
   },
   "outputs": [],
   "source": [
    "text_emotion_recognition.to_csv('../data/Original Data/text_emotion_recognition_updated.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NNDL Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
